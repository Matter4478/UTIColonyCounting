{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLO Image detection model tutorial\n",
        "This notebook contains all the steps you need to run an image detection model. The single-class remap is **optional**\n",
        "so you can keep your original multi-class dataset for later experiments.\n",
        "\n",
        "**Before running everything, what to install** (in the venv):\n",
        "1. VS and CUDA (for nvidia gpu)\n",
        "2. create and activate the venv\n",
        "3. pip install --upgrade pip setuptools wheel\n",
        "4. pip install ultralytics\n",
        "5. the correct version of pytorch (https://pytorch.org/get-started/locally/)\n",
        "\n",
        "**Sections**:\n",
        "1. Config\n",
        "2. Validate input layout\n",
        "3. (Optional) Remap to single class â†’ `DEST_SINGLE`\n",
        "4. Split into `train/val/test` from `DATASET_FOR_SPLIT`\n",
        "5. Write `data.yaml` (reads `classes.txt` if present; otherwise infers `nc`)\n",
        "6. Train (Ultralytics YOLO)\n",
        "7. Validate on test images\n",
        "\n",
        "\n",
        "**Expected input format** (no zip needed):\n",
        "```\n",
        "SRC_ROOT/\n",
        "  images/  (jpg, png, ...)\n",
        "  labels/  (txt per image: class cx cy w h ...)\n",
        "  classes.txt  (optional: one class name per line)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5b062ad",
      "metadata": {},
      "source": [
        "## 1) Configuration\n",
        "\n",
        "**This will probably be the only block that needs editing**; here is where most of the decision making is done:\n",
        "1. Make sure to choose the right paths\n",
        "2. Decide now if you want to use single-class or not \n",
        "3. Choose the ratio between training, validate and test in the data set\n",
        "4. Choose the YOLO model size you want to run; e.g. the 'm' in yolo11m stands for medium\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "# 1\n",
        "\n",
        "# Set the path to the original dataset\n",
        "SRC_ROOT = Path(r\"Path to the original dataset\")\n",
        "\n",
        "# Where to write the optional single-class copy:\n",
        "DEST_SINGLE = Path(r\"Path to the single-class copy\")\n",
        "\n",
        "# Output root for the split + data.yaml:\n",
        "OUT_ROOT = Path(r\"Path to the output root\")\n",
        "\n",
        "# 2\n",
        "\n",
        "# DATASET_FOR_SPLIT = SRC_ROOT  # change to DEST_SINGLE if you want a single-class copy\n",
        "DATASET_FOR_SPLIT = DEST_SINGLE # change to SRC_ROOT if you don't want a single-class copy\n",
        "\n",
        "\n",
        "# 3\n",
        "TRAIN_RATIO, VAL_RATIO, TEST_RATIO = 0.85, 0.10, 0.05\n",
        "SMALL_TEST_COUNT = None  # set None to disable and use ratios\n",
        "RANDOM_SEED = 42\n",
        "IMG_EXT = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
        "\n",
        "# Training options:\n",
        "MODEL_WEIGHTS = \"yolo11l.pt\"\n",
        "IMG_SIZE = 2016                 # This has to be a multiple of 32\n",
        "EPOCHS = 60\n",
        "BATCH = 1                       # This has to be a power of 2\n",
        "\n",
        "SRC_ROOT, DEST_SINGLE, DATASET_FOR_SPLIT, OUT_ROOT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Validate input layout\n",
        "Checks that `images/` and `labels/` exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_SRC = SRC_ROOT / \"images\"\n",
        "LBL_SRC = SRC_ROOT / \"labels\"\n",
        "assert IMG_SRC.exists() and IMG_SRC.is_dir(), f\"Missing images folder: {IMG_SRC}\"\n",
        "assert LBL_SRC.exists() and LBL_SRC.is_dir(), f\"Missing labels folder: {LBL_SRC}\"\n",
        "print(\"âœ… Found:\", IMG_SRC)\n",
        "print(\"âœ… Found:\", LBL_SRC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) (Optional) Remap to single class\n",
        "Run this **only if** you want a single-class dataset copy. Skip this cell to keep multiclass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "IMG_DST = DEST_SINGLE / \"images\"\n",
        "LBL_DST = DEST_SINGLE / \"labels\"\n",
        "IMG_DST.mkdir(parents=True, exist_ok=True)\n",
        "LBL_DST.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def rewrite_to_single_class(label_text: str) -> str:\n",
        "    out = []\n",
        "    for line in label_text.splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        parts = line.split()\n",
        "        if len(parts) >= 5:\n",
        "            parts[0] = \"0\"\n",
        "            out.append(\" \".join(parts))\n",
        "        else:\n",
        "            out.append(line)\n",
        "    return (\"\\n\".join(out) + \"\\n\") if out else \"\"\n",
        "\n",
        "imgs = sorted([p for p in IMG_SRC.rglob(\"*\") if p.suffix.lower() in IMG_EXT])\n",
        "pairs = []\n",
        "for im in imgs:\n",
        "    lb = LBL_SRC / f\"{im.stem}.txt\"\n",
        "    if lb.exists():\n",
        "        pairs.append((im, lb))\n",
        "\n",
        "if not pairs:\n",
        "    raise SystemExit(\"No image/label pairs found in SRC_ROOT.\")\n",
        "\n",
        "copied = 0\n",
        "for im, lb in pairs:\n",
        "    shutil.copy2(im, IMG_DST / im.name)\n",
        "    txt = lb.read_text(encoding=\"utf-8\")\n",
        "    remapped = rewrite_to_single_class(txt)\n",
        "    (LBL_DST / lb.name).write_text(remapped, encoding=\"utf-8\")\n",
        "    copied += 1\n",
        "\n",
        "(DEST_SINGLE / \"classes.txt\").write_text(\"colony\\n\", encoding=\"utf-8\")\n",
        "print(f\"âœ… Single-class copy complete. Pairs: {copied}\")\n",
        "print(\"Single-class dataset at:\", DEST_SINGLE)\n",
        "print(\"ðŸ‘‰ To use it in the split, set DATASET_FOR_SPLIT = DEST_SINGLE in the Config cell.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Split into train / val / test\n",
        "Run this to split either the multi or the single class data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import random, shutil\n",
        "\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "IMG_SRC2 = DATASET_FOR_SPLIT / \"images\"\n",
        "LBL_SRC2 = DATASET_FOR_SPLIT / \"labels\"\n",
        "\n",
        "imgs2 = sorted([p for p in IMG_SRC2.rglob(\"*\") if p.suffix.lower() in IMG_EXT])\n",
        "pairs2 = [(im, LBL_SRC2 / f\"{im.stem}.txt\") for im in imgs2 if (LBL_SRC2 / f\"{im.stem}.txt\").exists()]\n",
        "if not pairs2:\n",
        "    raise SystemExit(\"No pairs found in DATASET_FOR_SPLIT.\")\n",
        "\n",
        "random.shuffle(pairs2)\n",
        "N = len(pairs2)\n",
        "\n",
        "if SMALL_TEST_COUNT is not None:\n",
        "    test_n = min(SMALL_TEST_COUNT, N)\n",
        "    rem = N - test_n\n",
        "    tr = int(rem * (TRAIN_RATIO / (TRAIN_RATIO + VAL_RATIO)))\n",
        "    val_n = rem - tr\n",
        "    train_n = tr\n",
        "else:\n",
        "    test_n  = int(N * TEST_RATIO)\n",
        "    train_n = int(N * TRAIN_RATIO)\n",
        "    val_n   = N - train_n - test_n\n",
        "\n",
        "train_pairs = pairs2[:train_n]\n",
        "val_pairs   = pairs2[train_n:train_n+val_n]\n",
        "test_pairs  = pairs2[train_n+val_n:]\n",
        "\n",
        "OUT_IMG_T = OUT_ROOT / \"train\" / \"images\"\n",
        "OUT_LBL_T = OUT_ROOT / \"train\" / \"labels\"\n",
        "OUT_IMG_V = OUT_ROOT / \"val\" / \"images\"\n",
        "OUT_LBL_V = OUT_ROOT / \"val\" / \"labels\"\n",
        "OUT_IMG_S = OUT_ROOT / \"test\" / \"images\"\n",
        "OUT_LBL_S = OUT_ROOT / \"test\" / \"labels\"\n",
        "\n",
        "for p in [OUT_IMG_T, OUT_LBL_T, OUT_IMG_V, OUT_LBL_V, OUT_IMG_S, OUT_LBL_S]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def cp_pair(im: Path, lb: Path, di: Path, dl: Path):\n",
        "    shutil.copy2(im, di / im.name)\n",
        "    shutil.copy2(lb, dl / f\"{im.stem}.txt\")\n",
        "\n",
        "for im, lb in train_pairs: cp_pair(im, lb, OUT_IMG_T, OUT_LBL_T)\n",
        "for im, lb in val_pairs:   cp_pair(im, lb, OUT_IMG_V, OUT_LBL_V)\n",
        "for im, lb in test_pairs:  cp_pair(im, lb, OUT_IMG_S, OUT_LBL_S)\n",
        "\n",
        "print(f\"âœ… Split done. total={N}  train={len(train_pairs)}  val={len(val_pairs)}  test={len(test_pairs)}\")\n",
        "print(\"Split output root:\", OUT_ROOT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Write `data.yaml`\n",
        "- If `classes.txt` exists in already, uses it for `names` and `nc`\n",
        "- Otherwise, makes a new one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "classes_file = (DATASET_FOR_SPLIT / \"classes.txt\")\n",
        "names = None\n",
        "if classes_file.exists():\n",
        "    names = [ln.strip() for ln in classes_file.read_text(encoding=\"utf-8\").splitlines() if ln.strip()]\n",
        "\n",
        "if names is None:\n",
        "    # infer nc from labels\n",
        "    max_c = 0\n",
        "    for lbl in (OUT_ROOT / \"train\" / \"labels\").glob(\"*.txt\"):\n",
        "        for line in lbl.read_text(encoding=\"utf-8\").splitlines():\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            parts = line.split()\n",
        "            if len(parts) >= 5 and parts[0].isdigit():\n",
        "                cid = int(parts[0])\n",
        "                if cid > max_c:\n",
        "                    max_c = cid\n",
        "    nc = max_c + 1\n",
        "    names = [f\"class_{i}\" for i in range(nc)]\n",
        "else:\n",
        "    nc = len(names)\n",
        "\n",
        "yaml = f'''train: \"{(OUT_ROOT / 'train' / 'images').as_posix()}\"\n",
        "val:   \"{(OUT_ROOT / 'val'   / 'images').as_posix()}\"\n",
        "test:  \"{(OUT_ROOT / 'test'  / 'images').as_posix()}\"\n",
        "\n",
        "nc: {nc}\n",
        "names: {names}\n",
        "'''\n",
        "(OUT_ROOT / \"data.yaml\").write_text(yaml, encoding=\"utf-8\")\n",
        "print(\"âœ… Wrote:\", OUT_ROOT / \"data.yaml\")\n",
        "print(\"nc:\", nc, \"names:\", names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "815e321f",
      "metadata": {},
      "source": [
        "**Last check before training**: Make sure cuda is available and the GPU is used. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f9ba5eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"torch:\", torch.__version__)\n",
        "print(\"cuda available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"gpu:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Train\n",
        "Trains a YOLO model with the generated `data.yaml`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "data_yaml = OUT_ROOT / \"data.yaml\"\n",
        "model = YOLO(MODEL_WEIGHTS)\n",
        "model.train(data=str(data_yaml), imgsz=IMG_SIZE, epochs=EPOCHS, batch=BATCH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Validate\n",
        "Runs the latest 'best' run on the test dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "106584a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, glob, time\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image, display\n",
        "\n",
        "DATA_YAML   = OUT_ROOT / \"data.yaml\"\n",
        "TEST_IMAGES = OUT_ROOT / \"test\" / \"images\"\n",
        "\n",
        "# Finds the latest 'best' weights\n",
        "def latest_best_weights(root=\"runs/detect\"):\n",
        "    cand = []\n",
        "    for w in Path(root).glob(\"train*/weights/best.pt\"):\n",
        "        try:\n",
        "            mtime = w.stat().st_mtime\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "        cand.append((mtime, w))\n",
        "    if not cand:\n",
        "        raise FileNotFoundError(f\"No best.pt found under {root}/train*/weights/\")\n",
        "    cand.sort(key=lambda x: x[0], reverse=True)\n",
        "    return cand[0][1]\n",
        "\n",
        "BEST_WEIGHTS = str(latest_best_weights())\n",
        "print(f\"âœ… Using latest best weights: {BEST_WEIGHTS}\")\n",
        "\n",
        "\n",
        "model = YOLO(BEST_WEIGHTS)\n",
        "model.predict(\n",
        "    source=TEST_IMAGES,\n",
        "    save=True,\n",
        "    hide_labels=True,\n",
        "    hide_conf=True,\n",
        "    name=\"predict-test\",\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "metrics = model.val(\n",
        "    data=DATA_YAML,\n",
        "    split=\"test\",\n",
        "    plots=True,\n",
        "    save_json=True,\n",
        "    name=\"val-test\",\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "print(\"\\nðŸ“‚ Test-set evaluation artifacts saved in: runs/detect/val-test/\")\n",
        "print(\" - confusion_matrix.png\")\n",
        "print(\" - PR_curve.png\")\n",
        "print(\" - F1_curve.png\")\n",
        "print(\" - results.png\")\n",
        "print(\" - predictions.json\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.10)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
